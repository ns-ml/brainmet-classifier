{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>De-Ided #</th>\n",
       "      <th>Text</th>\n",
       "      <th>Number of Lesions</th>\n",
       "      <th>expected_group</th>\n",
       "      <th>Key_Sentence</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2914</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont Date/Time:  10...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Extensive enhancing mass</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2968</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont Date/Time:  09...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>enhancing metastatic lesion</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2990</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont Date/Time:  09...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>enhancing cystic mass</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2992</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont Date/Time:  07...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>enhancing lesion</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3147</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont Date/Time:  08...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Right parietal lesion</td>\n",
       "      <td>impression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   De-Ided #                                               Text  \\\n",
       "0       2914    Type:  MR Brain w AND w/oCont Date/Time:  10...   \n",
       "1       2968    Type:  MR Brain w AND w/oCont Date/Time:  09...   \n",
       "2       2990    Type:  MR Brain w AND w/oCont Date/Time:  09...   \n",
       "3       2992    Type:  MR Brain w AND w/oCont Date/Time:  07...   \n",
       "4       3147    Type:  MR Brain w AND w/oCont Date/Time:  08...   \n",
       "\n",
       "  Number of Lesions  expected_group                 Key_Sentence    Location  \n",
       "0                 1               1     Extensive enhancing mass  impression  \n",
       "1                 1               1  enhancing metastatic lesion  impression  \n",
       "2                 1               1        enhancing cystic mass  impression  \n",
       "3                 1               1             enhancing lesion  impression  \n",
       "4                 1               1       Right parietal lesion   impression  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('train_data.xlsx', 'data')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_report(report):\n",
    "    \"\"\"Extract and clean the whole report section from an MRI report.\n",
    "\n",
    "        Args:\n",
    "            report: MRI report string\n",
    "\n",
    "        Returns:\n",
    "            cleaned_report: all lower caps string \n",
    "            without any excess whitespace.\n",
    "    \"\"\"\n",
    "    cleaned_report_1 = report.strip().lower()\n",
    "    cleaned_report  = \" \".join(cleaned_report_1.split())\n",
    "    return cleaned_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_findings(report):\n",
    "    \"\"\"Extract and clean the FINDINGS section from an MRI report.\n",
    "\n",
    "        Args:\n",
    "            report: MRI report string\n",
    "\n",
    "        Returns:\n",
    "            findings: all lower caps string including the findings section\n",
    "            without any excess whitespace.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'''FINDINGS:(.*)IMPRESSION''')\n",
    "    findings_mo = re.search(pattern, report)\n",
    "    cleaned_findings = findings_mo.group(1).strip().lower()\n",
    "    findings = \" \".join(cleaned_findings.split())\n",
    "    return findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_impression(report):\n",
    "    \"\"\"Extract and clean the IMPRESSION section from an MRI report.\n",
    "\n",
    "        Args:\n",
    "            report: MRI report string\n",
    "\n",
    "        Returns:\n",
    "            findings: all lower caps string including the IMPRESSION section\n",
    "            without any excess whitespace.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'''IMPRESSION:(.*)''')\n",
    "    findings_mo = re.search(pattern, report)\n",
    "    cleaned_findings = findings_mo.group(1).strip().lower()\n",
    "    findings = \" \".join(cleaned_findings.split())\n",
    "    return findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_by_count(report):\n",
    "    \"\"\"From the impression of an MRI report, count the occurance of key words\n",
    "\n",
    "        Args:\n",
    "            report: MRI report string\n",
    "\n",
    "        Returns:\n",
    "            group: equal to number of lesions if group is 1,2, or 3. Anything >3 is group 4\n",
    "    \"\"\"\n",
    "    \n",
    "    findings = clean_impression(report)\n",
    "    #Tokenize into sentences\n",
    "    tok_findings = word_tokenize(findings)\n",
    "    \n",
    "    #Count number of times a word in key_words occurs\n",
    "    key_words = ['lesion', 'mass', 'metastasis', 'focus']\n",
    "    counts = Counter()\n",
    "    for word in tok_findings:\n",
    "        if word in key_words:\n",
    "            counts[word] +=1\n",
    "            \n",
    "    #Catagorize based on the number of occurances of the most common word\n",
    "    try:\n",
    "        lesions = counts.most_common(1)[0][1]\n",
    "        if lesions >= 4:\n",
    "            group = 4\n",
    "        else:\n",
    "            group = lesions\n",
    "    except:\n",
    "        group = 1\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def group_by_keyword(report):\n",
    "    \"\"\"Read the entire MRI report and look for key words to indicate multiplicity, if found stop and generate\n",
    "    group number. If not, proceed to group_by_count function\n",
    "\n",
    "        Args:\n",
    "            report: MRI report string\n",
    "\n",
    "        Returns:\n",
    "            group: 2,3,4 based on the presence of key words, else proceed to group_by_count\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_test = clean_report(report)\n",
    "    three_keywords = ['three', 'third lesion', '3rd lesion', '3 lesions']\n",
    "    two_keywords = ['two', 'second lesion', '2nd lesion', '2 lesions']\n",
    "    multiple_keywords = ['multiple', 'numerous', 'multifocal']\n",
    "\n",
    "    if any(word in clean_test for word in multiple_keywords):\n",
    "        group = 4\n",
    "    elif any(word in clean_test for word in three_keywords):\n",
    "        group = 3\n",
    "    elif any(word in clean_test for word in two_keywords):\n",
    "        group = 2 \n",
    "    else:\n",
    "        group = group_by_count(report)\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['calc_group'] = data['Text'].map(group_by_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.45      0.53        11\n",
      "          2       0.45      0.45      0.45        11\n",
      "          3       0.73      0.80      0.76        10\n",
      "          4       0.81      0.93      0.87        14\n",
      "\n",
      "avg / total       0.66      0.67      0.66        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(data['calc_group'], data['expected_group']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.to_csv('calc_train.csv')\n",
    "#!open calc_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Supervised Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = ['three', 'third lesion', '3rd lesion', '3 lesions',\n",
    "            'two', 'second lesion', '2nd lesion', '2 lesions',\n",
    "           'multiple', 'numerous', 'multifocal',\n",
    "           'mass', 'focus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in keywords:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(2 lesions)': False,\n",
       "  'contains(2nd lesion)': False,\n",
       "  'contains(3 lesions)': False,\n",
       "  'contains(3rd lesion)': False,\n",
       "  'contains(focus)': False,\n",
       "  'contains(mass)': True,\n",
       "  'contains(multifocal)': False,\n",
       "  'contains(multiple)': False,\n",
       "  'contains(numerous)': False,\n",
       "  'contains(second lesion)': False,\n",
       "  'contains(third lesion)': False,\n",
       "  'contains(three)': False,\n",
       "  'contains(two)': False},\n",
       " 1)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(list(data['Text'].map(word_tokenize)), list(data['Group ']))\n",
    "train_set = [(document_features(w),g) for (w,g) in zipped]\n",
    "train_set[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contains(two)', True),\n",
       " ('contains(multiple)', True),\n",
       " ('contains(focus)', True),\n",
       " ('contains(mass)', False),\n",
       " ('contains(two)', False)]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58695652173913049"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'h', 'last_letter': 'k', 'length': 5}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(word):\n",
    "    return{'last_letter': word[-1],\n",
    "           'length':len(word),\n",
    "           'first_letter':word[1]}\n",
    "\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-b0af0ccf5eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m names = ([(name, 'male') for name in names.words('male.txt')] + \n\u001b[0m\u001b[1;32m      2\u001b[0m [(name, 'female') for name in names.words('female.txt')])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "[(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuressets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set, test_test = featuressets[500:], featuressets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "print nltk.classify.accuracy(classifier, test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = u'a'           female : male   =     36.0 : 1.0\n",
      "             last_letter = u'k'             male : female =     32.0 : 1.0\n",
      "             last_letter = u'f'             male : female =     16.5 : 1.0\n",
      "             last_letter = u'p'             male : female =     12.5 : 1.0\n",
      "             last_letter = u'v'             male : female =     10.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names = names[1500:]\n",
    "devtest_names = names[500:1500]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = [(gender_features(n),g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n,g) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769\n"
     ]
    }
   ],
   "source": [
    "print nltk.classify.accuracy(classifier, devtest_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag,guess,name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for (tag, guess,name) in sorted(errors):\n",
    "    #print 'correct = %-8s guess = %-8s name = %-30s' % (tag, guess, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sucess', u'sonja', u'askew', u'woods', u'spiders']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = all_words.keys()[:2000]\n",
    "word_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features2(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    key_words = ['sans', 'wires']\n",
    "    for word in key_words:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features2(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(sans)': False, 'contains(wires)': False}, u'neg')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(sans) = True              neg : pos    =      9.0 : 1.0\n",
      "         contains(wires) = True              neg : pos    =      6.3 : 1.0\n",
      "          contains(sans) = False             pos : neg    =      1.0 : 1.0\n",
      "         contains(wires) = False             pos : neg    =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(sans)': False, 'contains(wires)': False}, u'neg')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
