{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on \"Python Machine Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group_x</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>2</td>\n",
       "      <td>Type:  MRI BRAIN W/WO CONTRAST\\nDate/Time:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>3</td>\n",
       "      <td>PROCEDURE: MR Brain WWO Contrast  HISTORY: 48-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group_x                                             Report\n",
       "1805        2    Type:  MRI BRAIN W/WO CONTRAST\\nDate/Time:  ...\n",
       "1806        3  PROCEDURE: MR Brain WWO Contrast  HISTORY: 48-..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/ramo/Dropbox/Stats/multiple-mets/data/labeled/final_dataset.xlsx')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Group_x': 'Group'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/ramo/Dropbox/Stats/multiple-mets/data/training/BWH_training7.3.16/2cat-Table 1.csv')\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop category 2 (not sure), and 3 (not met)\n",
    "# TODO: Resolve category 2 issues\n",
    "df = df[(df['Group'] == 1) | (df['Group'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0</td>\n",
       "      <td>PROCEDURE: MR BRAIN WITHOUT AND WITH CONTRAST ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1</td>\n",
       "      <td>Type:  MRI BRAIN W/WO CONTRAST\\nDate/Time:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>1</td>\n",
       "      <td>Type:  MR Brain w AND w/oCont \\nDate/Time:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>1</td>\n",
       "      <td>PROCEDURE: MR Brain WWO Contrast  HISTORY: 75-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>0</td>\n",
       "      <td>Type:  FMRI BRAIN BY TECH\\nDate/Time:  09/12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group                                             Report\n",
       "1807      0  PROCEDURE: MR BRAIN WITHOUT AND WITH CONTRAST ...\n",
       "1808      1    Type:  MRI BRAIN W/WO CONTRAST\\nDate/Time:  ...\n",
       "1809      1    Type:  MR Brain w AND w/oCont \\nDate/Time:  ...\n",
       "1810      1  PROCEDURE: MR Brain WWO Contrast  HISTORY: 75-...\n",
       "1811      0    Type:  FMRI BRAIN BY TECH\\nDate/Time:  09/12..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'PROCEDURE: MR Brain W Contrast   HISTORY:  Mass within the left superior frontal gyrus.  Also left temporoparietal meningioma.  Preoperative exam.  TECHNIQUE: Limited axial 3D MP-RAGE postcontrast with coronal and sagittal reformatted images images of the brain, for preoperative localization.  COMPARISON: MRI brain with and without contrast on June 6, 2009.  FINDINGS: As recently noted, there is a heterogeneously enhancing mass centered in the left superior frontal gyrus.  The mass measures 1.3-cm transverse by 1.6-cm AP by 1.4 cm CC (series 4 image 148 chemistry 100 image 39), not significant changed from recent measurements of 1.4 x 1.6 x 1.4 cm, respectively.  Inferior to the well-defined enhancing lesion, there is again noted to be a less well-defined area of increased signal, which demonstrated intrinsic T1 hyperintensity on the precontrast images of the June 6, 2009 exam.  The previously questioned superimposed enhancement, which is now difficult to assess given the lack of precontrast images.  This extends caudally by approximately 1.5 cm beyond the caudal aspect of the mass as seen on series 100 image 39.  There is surrounding T1 hypointensity which extends to the level of the left lateral ventricle, as well as laterally to the precentral gyrus.  There is mild cortical thickening and T1 hypointensity involving the cortex along the medial aspect of the enhancing mass, corresponding to previously noted FLAIR hyperintensity.  There is associated sulcal effacement along the paramedian left frontal lobe, as well as mass effect upon subjacent left lateral ventricle.   Other scattered areas of T1 hypointensity are seen in the periventricular and subcortical white matter, most consistent with minimal chronic small vessel ischemic changes.  No other definite areas of intra-axial pathologic enhancement are seen, although axial images are degraded by motion artifact.    There is a solidly enhancing extra-axial dural based mass in the left temporoparietal region, measuring 1.4 cm transverse by 1.6-cm AP by 1.6 cm CC (series 4 image 63, series 100 image 47).  There is no significant adjacent brain parenchymal edema with only mild localized mass effect.    The basal cisterns are patent.  There is no midline shift.  Note is again made of a left greater than right parasagittal arachnoid cyst crossing the midline near the vertex, presumably via a defect in the interhemispheric falx, or probably representing two adjacent arachnoid cysts.  The craniocervical junction is intact.   IMPRESSION:   1.  Stable appearance of enhancing lesion centered in the left superior frontal gyrus without significant change since the prior exam.  Stable appearance of additional increased T1 signal extending caudally from the caudal aspect of the mass, with previously questioned superimposed enhancement.  There is surrounding vasogenic edema.  Differential diagnosis again includes a solitary hemorrhagic metastasis or primary CNS tumor.  2.  Stable appearance of small left  temporoparietal extra-axial dural-based mass most consistent with a meningioma.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Report'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove puntuation, removed header/footer and attending attestation\n",
    "# TODO: keep decimels\n",
    "# If report fails several variations in syntax, mark as error and drop\n",
    "def preprocessor(text):\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    body_pattern = re.compile(r'findings (.*) (?=this report was)')\n",
    "    matched_text = body_pattern.search(text)\n",
    "    \n",
    "    if matched_text is None:\n",
    "        body_pattern = re.compile(r'findings (.*) (?=radiologists signatures)')\n",
    "        matched_text = body_pattern.search(text)\n",
    "        \n",
    "    if matched_text is None:\n",
    "        body_pattern = re.compile(r'comparison (.*) (?=radiologists signatures)')\n",
    "        matched_text = body_pattern.search(text)\n",
    "        \n",
    "    if matched_text is None:\n",
    "        stripped_text = 'ERROR'\n",
    "    else:\n",
    "        stripped_text = matched_text.group(1).replace(\n",
    "            'i the teaching physician have reviewed the images and agree with the report as written',\n",
    "            '')\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    # Remove date\n",
    "    date_pattern = r'[0-9]{1,2}[-/][0-9]{1,2}[-/][0-9]{2,}'\n",
    "    text = re.sub(date_pattern, '', text.lower())\n",
    "\n",
    "    # Remove newlines\n",
    "    text = text.replace('\\n', '')\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove punctution, keep decimal points\n",
    "    text = re.sub(r'[\\W]+(?!\\d)', ' ', text)\n",
    "    \n",
    "    # Remove the signature at the end of the report              \n",
    "    \n",
    "    if text.find('I the teaching physician') != -1:\n",
    "        body_pattern = re.compile(r'(.*) (?=i the teaching physician)')\n",
    "        matched_text = body_pattern.search(text).group(1)\n",
    "        \n",
    "    elif text.find('end of impression') != -1:\n",
    "        body_pattern = re.compile(r'(.*) (?=end of impression)')\n",
    "        matched_text = body_pattern.search(text).group(1)\n",
    "    \n",
    "    elif text.find('radiologists signatures') != -1:\n",
    "        body_pattern = re.compile(r'(.*) (?=radiologists signatures)')\n",
    "        matched_text = body_pattern.search(text).group(1)\n",
    "    \n",
    "    else:\n",
    "        matched_text = text\n",
    "        \n",
    "    return matched_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Add named entity recognition to reduce report noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ae58834671cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_report'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ramo/.conda/envs/notebook/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-94c95e471fc1>\u001b[0m in \u001b[0;36mpreprocessor\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'radiologists signatures'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbody_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(.*) (?=radiologists signatures)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmatched_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "df['clean_report'] = df['Report'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_rows = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = df.query(\"clean_report == ['ERROR']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors found: 1195. Rows with errors will be dropped\n"
     ]
    }
   ],
   "source": [
    "print('Number of errors found: '+str(errors.shape[0])+'. Rows with errors will be dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['clean_report'] != 'ERROR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_rows = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 1479\n",
      "Final rows: 284\n"
     ]
    }
   ],
   "source": [
    "print('Original rows: '+str(original_rows)+'\\nFinal rows: '+str(final_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('train_dataOA7.19.16.csv', columns=['clean_report', 'Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['Report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>clean_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>1</td>\n",
       "      <td>n n brain mri 1 6 x 2 8 cm right peripheral ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>0</td>\n",
       "      <td>n n again seen is the right superior temporal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group                                       clean_report\n",
       "1809      1  n n brain mri 1 6 x 2 8 cm right peripheral ce...\n",
       "1811      0  n n again seen is the right superior temporal ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokinizing documents, stemming, stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Try porter2 and lancaster stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_modified = [w for w in stop if w not in ['no', 'not']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Old manual split, non-random. Replace w/ random sampling from pandas method\n",
    "# x_train = df.loc[:170, 'clean_report'].values\n",
    "# y_train = df.loc[:170, 'Group'].values\n",
    "# x_test = df.loc[170:, 'clean_report'].values\n",
    "# y_test = df.loc[170:, 'Group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8, random_state = 0)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = train_df.loc[:, 'clean_report'].values\n",
    "y_train = train_df.loc[:, 'Group'].values\n",
    "x_test = test_df.loc[:, 'clean_report'].values\n",
    "y_test = test_df.loc[:, 'Group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                       lowercase=False,\n",
    "                       preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [{'vect__ngram_range': [(1,1), (1,2)],\n",
    "              'vect__stop_words': [stop, stop_modified, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "             {'vect__ngram_range': [(1,1), (1,2)],\n",
    "              'vect__stop_words': [stop, stop_modified, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "              'vect__use_idf': [False],\n",
    "              'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]}\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                    ('clf', LogisticRegression(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                          scoring='accuracy',\n",
    "                          cv=5, verbose=1,\n",
    "                          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tru...nalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'vect__ngram_range': [(1, 1), (1, 2)], 'vect__tokenizer': [<function tokenizer at 0x10fd55b18>, <function tokenizer_porter at 0x10fd55c80>], 'clf__penalty': ['l1', 'l2'], 'clf__C': [1.0, 10.0, 100.0], 'vect__stop_words': [[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselv...x10fd55c80>], 'vect__use_idf': [False], 'clf__C': [1.0, 10.0, 100.0], 'clf__penalty': ['l1', 'l2']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'vect__ngram_range': (1, 1), 'vect__tokenizer': <function tokenizer at 0x10fd55b18>, 'clf__penalty': 'l1', 'clf__C': 10.0, 'vect__stop_words': None} \n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "print('CV Accuracy: %.3f'% gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.810\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %.3f' % clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf, 'clf/logregression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'clf/logregression.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0dab86d66567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf/logregression.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ramo/.conda/envs/notebook/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0mwas\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marrays\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmemmaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \"\"\"\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;31m# We are careful to open the file handle early and keep it open to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# avoid race-conditions on renames. That said, if data are stored in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'clf/logregression.pkl'"
     ]
    }
   ],
   "source": [
    "clf = joblib.load('clf/logregression.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from benchmark_binary_classifier import plot_confusion_matrix, benchmark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the outcomes of the testing set\n",
      "Done in 0.011735s\n",
      "Classification report on test set for classifier:\n",
      "Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tru...nalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79        18\n",
      "          1       0.86      0.79      0.83        24\n",
      "\n",
      "avg / total       0.81      0.81      0.81        42\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 5 19]]\n"
     ]
    }
   ],
   "source": [
    "benchmark(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEpCAYAAADxvLvMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1043e9690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using automatic model/hyperparameters selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Models\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import linear_model, svm, tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def concatenate(d1,d2):\n",
    "    d = d1.copy()\n",
    "    d.update(d2)\n",
    "    return d\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/Users/oarnaout/Dropbox/Stats/multiple-mets/')\n",
    "import sklearnextensions as sklx\n",
    "import printers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifiers and parameters to consider\n",
    "feature_parameters  = {\n",
    "                'vect__binary':(False, True),\n",
    "               'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "               'vect__analyzer' : ('word', 'char_wb')}\n",
    "\n",
    "nb_feature_parameters  = {'vect__ngram_range': ((1,1),(1,2),(1,3)),\n",
    "               'vect__analyzer' : ('word', 'char_wb')}\n",
    "use_spare_array = True\n",
    "use_binary_features = True\n",
    "classifiers = ({\n",
    "    'logistic_regression':(linear_model.LogisticRegression(),\n",
    "                           use_spare_array,\n",
    "                           not use_binary_features,\n",
    "                           concatenate(feature_parameters, {'clf__C': [1/x for x in [0.01, 0.1, 0.3, 1.0, 3.0, 10.0]]})),\n",
    "    'svm_linear':(svm.LinearSVC(tol=1e-6),\n",
    "                  use_spare_array,\n",
    "                  not use_binary_features,\n",
    "                  concatenate(feature_parameters, {'clf__C': [1/x for x in [0.01, 0.1, 0.3, 1.0, 3.0, 10.0]]})),\n",
    "    'svm_gaussian':(svm.SVC(tol=1e-6, kernel='rbf'),\n",
    "                    use_spare_array,\n",
    "                    not use_binary_features,\n",
    "                    concatenate(feature_parameters, {'clf__gamma': [.01, .03, 0.1],\n",
    "                                             'clf__C': [1/x for x in [0.01, 0.1, 0.3, 1.0, 3.0, 10.0]]})),\n",
    "    'decision_tree':(tree.DecisionTreeClassifier(criterion='entropy', random_state=RandomState(seed)),\n",
    "                     not use_spare_array,\n",
    "                     not use_binary_features,\n",
    "                     concatenate(feature_parameters,{'clf__max_depth': [2, 3, 4, 5, 6, 7 , 8, 9, 10, 15, 20]})),\n",
    "    'random_forest':(RandomForestClassifier(criterion='entropy', random_state=RandomState(seed)),\n",
    "                     not use_spare_array,\n",
    "                     not use_binary_features,\n",
    "                     concatenate(feature_parameters,{'clf__max_depth': [2, 3, 4, 5],\n",
    "                                                     'clf__n_estimators': [5, 25, 50, 100, 150, 200]})),\n",
    "    'naive_bayes':(BernoulliNB(alpha=1.0, binarize=None, fit_prior=True, class_prior=None),\n",
    "                   use_spare_array,\n",
    "                   use_binary_features,\n",
    "                   {'vect__ngram_range':((1,1),(1,2),(1,3)),\n",
    "                    'vect__analyzer':('word', 'char_wb')})\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = 'text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "for key, value in classifiers.items():\n",
    "    clf = value[0] #classifier\n",
    "    usa = value[1] #use sparse array\n",
    "    ubf = value[2] #use binary (for NB)\n",
    "    parameters = value[3]\n",
    "    vectorizer = CountVectorizer(input='content', decode_error='ignore', preprocessor=None, binary=ubf)\n",
    "    pipeline = (Pipeline(steps=[('vect', vectorizer),('clf',clf)]) if usa\n",
    "                    else Pipeline(steps=[('vect', vectorizer),('sa',sklx.SparseToArray()),('clf',clf)]))\n",
    "    gs = sklx.grid_analysis(pipeline, parameters, x_train, y_train)\n",
    "    printers.print_grid_search_results(gs,key,out_file, x_test, y_test)\n",
    "    if gs.best_score_>best_accuracy:\n",
    "        final_clf = gs.best_estimator_\n",
    "        best_accuracy = final_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: add model persistence to prevent re-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of core learning (for partial fit hashing vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer_porter(text):\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    tokenized = [porter.stem(word) for word in text]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open('train_dataOA7.19.16.csv', 'r') as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text, label = line[2:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                        n_features=2**21,\n",
    "                        preprocessor=None,\n",
    "                        tokenizer=tokenizer_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='log', random_state=1, n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_stream = stream_docs(path='./train_dataOA7.19.16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pbar = pyprind.ProgBar(1)\n",
    "classes = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range (1):\n",
    "    x_train, y_train = get_minibatch(doc_stream, size=170)\n",
    "    if not x_train:\n",
    "        break\n",
    "    x_train = vect.transform(x_train)\n",
    "    clf.partial_fit(x_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test, y_test = get_minibatch(doc_stream, size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f' % clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "benchmark(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing fitted scikit-learn estimators using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest = os.path.join('reportclassifier', 'pkl_objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'),\n",
    "           protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf,\n",
    "           open(os.path.join(dest, 'classifier.pkl'), 'wb'),\n",
    "           protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
